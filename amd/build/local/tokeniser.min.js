/*
 * @module     local_deepler/deepler
 * @copyright  2024 Bruno Baudry <bruno.baudry@bfh.ch>
 * @license    http://www.gnu.org/copyleft/gpl.html GNU GPL v3 or later
 */
define("local_deepler/local/tokeniser",[],(()=>{const patterns=[{regex:/<pre\b[^>]*>(.*?)<\/pre>/gs,type:"PRETAG"},{regex:/\$\$.*?\$\$/g,type:"LATEX"}],escapeReplacementString=str=>str.replace(/\$/g,"$$$$");return{postprocess:(text,expressions)=>(expressions.forEach((expr=>{const token=new RegExp(expr.token,"g");text=text.replace(token,escapeReplacementString(expr.expression))})),text),preprocess:(text,escapePatterns)=>{const expressions=[];let tokenizedText=text;return patterns.forEach((pattern=>{escapePatterns[pattern.type]&&(tokenizedText=tokenizedText.replace(pattern.regex,(match=>{const token="__".concat(pattern.type,"_").concat(expressions.length,"__");return expressions.push({token:token,expression:match}),token})))})),{tokenizedText:tokenizedText,expressions:expressions}}}}));

//# sourceMappingURL=tokeniser.min.js.map