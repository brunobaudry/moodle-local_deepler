define("local_deepler/local/tokeniser",["exports"],function(_exports){Object.defineProperty(_exports,"__esModule",{value:!0}),_exports.escapeReplacementString=escapeReplacementString,_exports.postprocess=function(text,expressions){return expressions.forEach(expr=>{const token=new RegExp(expr.token,"g");text=text.replace(token,escapeReplacementString(expr.expression))}),text},_exports.preprocess=function(text,escapePatterns){const expressions=[];let tokenizedText=text;return patterns.forEach(pattern=>{escapePatterns[pattern.type]&&(tokenizedText=tokenizedText.replace(pattern.regex,match=>{const token=`__${pattern.type}_${expressions.length}__`;return expressions.push({token:token,expression:match}),token}))}),{tokenizedText:tokenizedText,expressions:expressions}};
/*
   * @module     local_deepler/deepler
   * @copyright  2024 Bruno Baudry <bruno.baudry@bfh.ch>
   * @license    http://www.gnu.org/copyleft/gpl.html GNU GPL v3 or later
   */
const patterns=[{regex:/<pre\b[^>]*>(.*?)<\/pre>/gs,type:"PRETAG"},{regex:/\$\$.*?\$\$/g,type:"LATEX"}];function escapeReplacementString(str){return str.replace(/\$/g,"$$$$")}});

//# sourceMappingURL=tokeniser.min.js.map