define("local_deepler/tokeniser",["exports"],(function(_exports){Object.defineProperty(_exports,"__esModule",{value:!0}),_exports.escapeReplacementString=escapeReplacementString,_exports.postprocess=function(text,expressions){return expressions.forEach((expr=>{const token=new RegExp(expr.token,"g");text=text.replace(token,escapeReplacementString(expr.expression))})),text},_exports.preprocess=function(text,escapePatterns){const expressions=[];let tokenizedText=text;return patterns.forEach((pattern=>{escapePatterns[pattern.type]&&(tokenizedText=tokenizedText.replace(pattern.regex,(match=>{const token="__".concat(pattern.type,"_").concat(expressions.length,"__");return expressions.push({token:token,expression:match}),token})))})),{tokenizedText:tokenizedText,expressions:expressions}};
/*
   * @module     local_deepler/deepler
   * @copyright  2024 Bruno Baudry <bruno.baudry@bfh.ch>
   * @license    http://www.gnu.org/copyleft/gpl.html GNU GPL v3 or later
   */
const patterns=[{regex:/<pre\b[^>]*>(.*?)<\/pre>/gs,type:"PRETAG"},{regex:/\$\$.*?\$\$/g,type:"LATEX"}];function escapeReplacementString(str){return str.replace(/\$/g,"$$$$")}}));

//# sourceMappingURL=tokeniser.min.js.map