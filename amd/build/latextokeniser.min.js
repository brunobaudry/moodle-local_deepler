define("local_deepler/latextokeniser",["exports"],(function(_exports){function escapeReplacementString(str){return str.replace(/\$/g,"$$$$")}Object.defineProperty(_exports,"__esModule",{value:!0}),_exports.escapeReplacementString=escapeReplacementString,_exports.postprocess=function(text,latexExpressions){return latexExpressions.forEach(((expr,i)=>{const token=new RegExp(`__LATEX_${i}__`,"g");text=text.replace(token,escapeReplacementString(expr))})),text},_exports.preprocess=
/*
   * @module     local_deepler/deepler
   * @copyright  2024 Bruno Baudry <bruno.baudry@bfh.ch>
   * @license    http://www.gnu.org/copyleft/gpl.html GNU GPL v3 or later
   */
function(text){const latexExpressions=[];let tokenizedText=text;return[{regex:/\$\$.*?\$\$/g,type:"display"}].forEach((pattern=>{tokenizedText=tokenizedText.replace(pattern.regex,(match=>{const token=`__LATEX_${latexExpressions.length}__`;return latexExpressions.push(match),token}))})),{tokenizedText:tokenizedText,latexExpressions:latexExpressions}}}));

//# sourceMappingURL=latextokeniser.min.js.map